{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeJZJm4YYtJ5"
      },
      "source": [
        "# Recommendation Systems – Frequent Pattern Mining\n",
        "\n",
        "* Name: Benedictus Bimo Cahyo Wicaksono<br>\n",
        "* Student ID: 5025201097<br>\n",
        "* Class: Big Data<br>\n",
        "* Lecturer: Abdul Munif, S.Kom., M.Sc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5tt8CLdL01j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b07cb6a6-c943-4fed-e728-9742b35c8e81"
      },
      "source": [
        "# To be able to use your data stored in your Google Drive you first need to mount your Google Drive so you can load and save files to it. \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#You'll need to put in a token which Google will generate for you as soon as you click on the link"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount the Google Drive so that I can load the dataset from my drive."
      ],
      "metadata": {
        "id": "vYxvbACzctDO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STJmV4kN8wOc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "27d61a34-f76f-4c40-9ff1-6bd3fe27fc18"
      },
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "csv_file = '/content/gdrive/MyDrive/Institut Teknologi Sepuluh Nopember/Mata Kuliah/Semester 6/Big Data/Mid Test/market-basket.csv'\n",
        "\n",
        "with open(csv_file, 'r') as f:\n",
        "    temp_lines = f.readline() + '\\n' + f.readline()\n",
        "    dialect = csv.Sniffer().sniff(temp_lines, delimiters=';,')\n",
        "    f.seek(0)\n",
        "    data = pd.read_csv(f, dialect=dialect, error_bad_lines=False)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-0ebf7a675779>:10: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  data = pd.read_csv(f, dialect=dialect, error_bad_lines=False)\n",
            "<ipython-input-3-0ebf7a675779>:10: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv(f, dialect=dialect, error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   BillNo                             Itemname  Quantity              Date  \\\n",
              "0  536365   WHITE HANGING HEART T-LIGHT HOLDER         6  01.12.2010 08:26   \n",
              "1  536365                  WHITE METAL LANTERN         6  01.12.2010 08:26   \n",
              "2  536365       CREAM CUPID HEARTS COAT HANGER         8  01.12.2010 08:26   \n",
              "3  536365  KNITTED UNION FLAG HOT WATER BOTTLE         6  01.12.2010 08:26   \n",
              "4  536365       RED WOOLLY HOTTIE WHITE HEART.         6  01.12.2010 08:26   \n",
              "\n",
              "  Price  CustomerID         Country  \n",
              "0  2,55     17850.0  United Kingdom  \n",
              "1  3,39     17850.0  United Kingdom  \n",
              "2  2,75     17850.0  United Kingdom  \n",
              "3  3,39     17850.0  United Kingdom  \n",
              "4  3,39     17850.0  United Kingdom  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f46c4c11-93c0-4b08-9676-9b56669d3386\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BillNo</th>\n",
              "      <th>Itemname</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>Date</th>\n",
              "      <th>Price</th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>Country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>536365</td>\n",
              "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
              "      <td>6</td>\n",
              "      <td>01.12.2010 08:26</td>\n",
              "      <td>2,55</td>\n",
              "      <td>17850.0</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>536365</td>\n",
              "      <td>WHITE METAL LANTERN</td>\n",
              "      <td>6</td>\n",
              "      <td>01.12.2010 08:26</td>\n",
              "      <td>3,39</td>\n",
              "      <td>17850.0</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>536365</td>\n",
              "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
              "      <td>8</td>\n",
              "      <td>01.12.2010 08:26</td>\n",
              "      <td>2,75</td>\n",
              "      <td>17850.0</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>536365</td>\n",
              "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
              "      <td>6</td>\n",
              "      <td>01.12.2010 08:26</td>\n",
              "      <td>3,39</td>\n",
              "      <td>17850.0</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>536365</td>\n",
              "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
              "      <td>6</td>\n",
              "      <td>01.12.2010 08:26</td>\n",
              "      <td>3,39</td>\n",
              "      <td>17850.0</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f46c4c11-93c0-4b08-9676-9b56669d3386')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f46c4c11-93c0-4b08-9676-9b56669d3386 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f46c4c11-93c0-4b08-9676-9b56669d3386');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After load the dataset, I have to split the columns because it is a *csv* file."
      ],
      "metadata": {
        "id": "tMgBiXFhcy0D"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmS1fIBvHO67"
      },
      "source": [
        "## Market Basket Analysis\n",
        "\n",
        "Market basket analysis is a data mining technique used by retailers to increase sales by better understanding customer purchasing patterns. It involves analyzing large data sets, such as purchase history, to reveal product groupings, as well as products that are likely to be purchased together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cyEVLpVJEIx"
      },
      "source": [
        "%%capture\n",
        "!sudo apt-get update --fix-missing\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "#!wget -q https://downloads.apache.org/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "\n",
        "!mv spark-3.0.0-bin-hadoop3.2.tgz sparkkk\n",
        "!tar xf sparkkk\n",
        "!pip install -q findspark"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5FUu1gKuTXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "873ad1c8-4942-4605-c8fe-701938e663d4"
      },
      "source": [
        "!pip install spark"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spark in /usr/local/lib/python3.9/dist-packages (0.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ps aux | grep py4j"
      ],
      "metadata": {
        "id": "6rn9Eqrrh0cR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e39732d4-5dc3-4991-9850-08d3a1148105"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root        7065  0.0  0.0   6904  3328 ?        S    02:35   0:00 /bin/bash -c ps aux | grep py4j\n",
            "root        7067  0.0  0.0   6312   720 ?        R    02:35   0:00 grep py4j\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9vONupGJe0H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "ba524f58-526e-4cb0-f663-6b6d5ee36693"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName('fpgrowth') \\\n",
        "    .master('local[*]') \\\n",
        "    .config('spark.sql.execution.arrow.pyspark.enabled', True) \\\n",
        "    .config('spark.sql.session.timeZone', 'UTC') \\\n",
        "    .config('spark.driver.memory','32G') \\\n",
        "    .config('spark.ui.showConsoleProgress', True) \\\n",
        "    .config('spark.sql.repl.eagerEval.enabled', True) \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark   "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f5a4caf9100>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://19eb5849a0ac:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXVurpFrJrO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f65b4126-2621-4f0f-eb9c-e73c27c19cea"
      },
      "source": [
        "from google.colab import files\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.fpm import FPGrowth\n",
        "\n",
        "data['BillNo'] = data['BillNo'].astype(str)\n",
        "data['Itemname'] = data['Itemname'].astype(str)\n",
        "\n",
        "sparkdata = spark.createDataFrame(data)\n",
        "basketdata = sparkdata.dropDuplicates(['BillNo', 'Itemname']).sort('BillNo')\n",
        "basketdata = basketdata.groupBy(\"BillNo\").agg(F.collect_list(\"Itemname\")).sort('BillNo')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/spark-3.0.0-bin-hadoop3.2/python/pyspark/sql/pandas/conversion.py:419: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  arrow_data = [[(c, t) for (_, c), t in zip(pdf_slice.iteritems(), arrow_types)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before I start the market basket analysis, I have decided to use *Billno* and *Itemname* for the columns. I had to convert them to *str* due to the type difference between both columns."
      ],
      "metadata": {
        "id": "XKQvXpAKe2AH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### minSupport = 0.006 and minConfidence = 0.006"
      ],
      "metadata": {
        "id": "9MU97mASds1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, I am using minSupport=0.006, minConfidence=0.006 for the FPGrowth."
      ],
      "metadata": {
        "id": "OIzkJ9TpfLHL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFAFXMQ7Jr1j"
      },
      "source": [
        "#Frequent Pattern Growth – FP Growth is a method of mining frequent itemsets\n",
        "fpGrowth = FPGrowth(itemsCol=\"collect_list(Itemname)\", minSupport=0.006, minConfidence=0.006) \n",
        "model = fpGrowth.fit(basketdata)\n",
        "\n",
        "# Display frequent itemsets.\n",
        "model.freqItemsets.show()\n",
        "items = model.freqItemsets\n",
        "# Display generated association rules.\n",
        "model.associationRules.show()\n",
        "rules = model.associationRules\n",
        "# transform examines the input items against all the association rules and summarize the\n",
        "# consequents as prediction\n",
        "model.transform(basketdata).show()\n",
        "transformed = model.transform(basketdata)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find frequent itemsets and association rules from transaction data stored in the basketdata DataFrame using PySpark, I had set the minimum support threshold and minimum confidence threshold. After that, I print the generated frequent itemsets and association rules. It also used the generated model to make predictions on new transaction data."
      ],
      "metadata": {
        "id": "1Epx6_MOgmc4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr2ZngKxik-s"
      },
      "source": [
        "# Convert the Spark DataFrame back to a Pandas DataFrame using Arrow\n",
        "result_pdf = items.select(\"*\").toPandas()\n",
        "result_pdf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to2XSdrqbxNQ"
      },
      "source": [
        "result_pdf.to_excel('result_pdfItemsFreq.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export the xlsx."
      ],
      "metadata": {
        "id": "GXfx0I44grag"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9V3qjpdj4Bt"
      },
      "source": [
        "rules_pdf = rules.select(\"*\").toPandas()\n",
        "rules_pdf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZNw7HS8b41n"
      },
      "source": [
        "rules_pdf.to_excel('rules_pdfAnteConseConfLift.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhcF2ldEj_Sn"
      },
      "source": [
        "transformed_pdf = transformed.select(\"*\").toPandas()\n",
        "transformed_pdf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7bNauaGcA4J"
      },
      "source": [
        "transformed_pdf.to_excel('transformed_pdfSalesTransactionIDCollectListPred.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### minSupport = 0.05 and minConfidence = 0.05"
      ],
      "metadata": {
        "id": "919quvlRd4Of"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, I am using minSupport=0.05, minConfidence=0.05 for the FPGrowth."
      ],
      "metadata": {
        "id": "QTrzL8tXg2hi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huk-xc1-d4Of"
      },
      "source": [
        "#Frequent Pattern Growth – FP Growth is a method of mining frequent itemsets\n",
        "fpGrowth = FPGrowth(itemsCol=\"collect_list(Itemname)\", minSupport=0.003, minConfidence=0.003) \n",
        "model = fpGrowth.fit(basketdata)\n",
        "\n",
        "# Display frequent itemsets.\n",
        "model.freqItemsets.show()\n",
        "items = model.freqItemsets\n",
        "# Display generated association rules.\n",
        "model.associationRules.show()\n",
        "rules = model.associationRules\n",
        "# transform examines the input items against all the association rules and summarize the\n",
        "# consequents as prediction\n",
        "model.transform(basketdata).show()\n",
        "transformed = model.transform(basketdata)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find frequent itemsets and association rules from transaction data stored in the basketdata DataFrame using PySpark, I had set the minimum support threshold and minimum confidence threshold. After that, I print the generated frequent itemsets and association rules. It also used the generated model to make predictions on new transaction data."
      ],
      "metadata": {
        "id": "JFoSgkJwg6V4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un0yyB4zd4Of"
      },
      "source": [
        "# Convert the Spark DataFrame back to a Pandas DataFrame using Arrow\n",
        "result_pdf = items.select(\"*\").toPandas()\n",
        "result_pdf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gp3M82Od4Of"
      },
      "source": [
        "result_pdf.to_excel('result_pdfItemsFreq1.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export the xlsx."
      ],
      "metadata": {
        "id": "f5BD1iMng9rk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXqTxLu_d4Of"
      },
      "source": [
        "rules_pdf = rules.select(\"*\").toPandas()\n",
        "rules_pdf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olgrmkGod4Og"
      },
      "source": [
        "rules_pdf.to_excel('rules_pdfAnteConseConfLift1.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XkEPUTTd4Og"
      },
      "source": [
        "transformed_pdf = transformed.select(\"*\").toPandas()\n",
        "transformed_pdf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVg4pGL1d4Og"
      },
      "source": [
        "transformed_pdf.to_excel('transformed_pdfSalesTransactionIDCollectListPred1.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "Normally, increasing the minimum support and confidence thresholds can lead to fewer but more meaningful rules and associations being discovered, as only the strongest associations will meet the higher thresholds. Based on the experiments with minSupport = 0.006 and minConfidence = 0.006 compared to minSupport = 0.003 and minConfidence = 0.003, it is concluded that a very high minimum support or confidence may result in too few rules to be of any practical use, while a very low minimum support or confidence may result in a large number of weak or spurious rules."
      ],
      "metadata": {
        "id": "pJAb-7WEmiqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem\n",
        "\n",
        "During this mid test, I faced a several problems related to the connection. I had successfully run my code for the 1st time, but when I re run it again, there were errors everywhere. The reason why I re run the code again is because I want to make sure everything before exporting the *xlsx* file.\n",
        "\n",
        "\n",
        "*Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:34797)*"
      ],
      "metadata": {
        "id": "lfCOe8S7o6oY"
      }
    }
  ]
}